{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"I Fought the Law\"\n",
    "### Contesting Charges in Virginia's District Courts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as pytools\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as pyo\n",
    "import cufflinks as cf\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pytools.set_credentials_file(username='katerdowdy', api_key='hBCWsR3iY9a1feRSpU2A')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.read_csv('./summary_county_data.csv')\n",
    "df_agg = pd.read_csv('./aggregate_charge_data.csv')\n",
    "df_full = pd.read_csv('./2017_full.csv')\n",
    "\n",
    "df_summary = df_summary.sort_values(by = 'Court')\n",
    "counties = list(df_summary['Court'].unique())\n",
    "df_agg = df_agg.sort_values(by = 'ChargeType')\n",
    "charges = list(df_agg['ChargeType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chloropleth(selection):\n",
    "    try:\n",
    "        fips = df_summary['full_fips']\n",
    "        values = df_summary[selection]\n",
    "        step1 = values.mean() / 5\n",
    "        step2 = (max(values) - values.mean()) / 5\n",
    "        step3 = (max(values) / 10)\n",
    "        num_endpoints = [np.round((values.mean() - (step1 * 4)), -3),\n",
    "                    np.round((values.mean() - (step1 * 3)), -3),\n",
    "                    np.round((values.mean() - (step1 * 2)), -3),\n",
    "                    np.round((values.mean() - step1), -3),\n",
    "                    np.round((values.mean()), -3),\n",
    "                    np.round((max(values) - (step2 * 4)), -3),\n",
    "                    np.round((max(values) - (step2 * 3)), -3),\n",
    "                    np.round((max(values) - (step2 * 2)), -3),\n",
    "                    np.round((max(values) - step2), -3)]\n",
    "        prop_endpoints = [.1, .2, .3, .4, .5, .6, .8, 1, 1.2]\n",
    "        even_endpoints = [step3, (step3 * 2), (step3 * 3), (step3 * 4), (step3 * 5),\n",
    "                         (step3 * 6), (step3 * 7), (step3 * 8), (step3 * 9)]\n",
    "    \n",
    "        colorscale = [\"#eafcfd\", \"#b7e0e4\", \"#85c5d3\", \"#60a7c7\", \"#4989bc\",\n",
    "               \"#3e6ab0\", \"#3d4b94\", \"#323268\", \"#1d1d3b\", \"#030512\"]\n",
    "        \n",
    "        fig = ff.create_choropleth(fips = fips, \n",
    "                           values = values,\n",
    "                          scope = ['VA'],\n",
    "                          county_outline={'color': 'rgb(169,169,169)', 'width': 1},\n",
    "                           exponent_format=True,\n",
    "                           #binning_endpoints = hearing_endpoints,\n",
    "                           binning_endpoints = num_endpoints,\n",
    "                          colorscale = colorscale,\n",
    "                           legend_title=selection)\n",
    "        return py.iplot(fig, filename=selection)\n",
    "            \n",
    "    except:\n",
    "        fig = ff.create_choropleth(fips = fips, \n",
    "                           values = values,\n",
    "                          scope = ['VA'],\n",
    "                          county_outline={'color': 'rgb(169,169,169)', 'width': 1},\n",
    "                           exponent_format=True,\n",
    "                           #binning_endpoints = hearing_endpoints,\n",
    "                           binning_endpoints = even_endpoints,\n",
    "                          colorscale = colorscale,\n",
    "                           legend_title=selection)\n",
    "        return py.iplot(fig, filename=selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['county_hearings', 'county_fines_charged', 'county_sentencing',\n",
    "          'county_probation', 'defense_win_rate', 'Population',\n",
    "          'fines_per_capita', 'hearings_per_capita']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hearings by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~katerdowdy/11.embed\" height=\"450px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chloropleth('county_hearings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where Defenses Are Won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~katerdowdy/19.embed\" height=\"450px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chloropleth('defense_win_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chloro = interactive(chloropleth, selection = ['county_hearings', 'county_fines_charged', \n",
    "                                               'county_sentencing',\n",
    "          'county_probation', 'defense_win_rate', 'Population',\n",
    "          'fines_per_capita', 'hearings_per_capita'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'CaseType', 'ChargeType', 'agg_charge',\n",
       "       'agg_charge_overturn_rate', 'agg_contested_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agg_charges(casetype):\n",
    "    trace1 = go.Bar(\n",
    "        x=df_agg[df_agg['CaseType'] == casetype]['ChargeType'],\n",
    "        y=df_agg[df_agg['CaseType'] == casetype]['agg_charge'],\n",
    "        name='All Charges'\n",
    "    )\n",
    "    trace2 = go.Bar(\n",
    "        x=df_agg[df_agg['CaseType'] == casetype]['ChargeType'],\n",
    "        y=df_agg[df_agg['CaseType'] == casetype]['agg_charge'] * df_agg[df_agg['CaseType'] == casetype]['agg_contested_rate'],\n",
    "        name='Defendants Went to Court'\n",
    "    )\n",
    "\n",
    "    trace3 = go.Bar(\n",
    "        x=df_agg[df_agg['CaseType'] == casetype]['ChargeType'],\n",
    "        y=df_agg[df_agg['CaseType'] == casetype]['agg_charge'] * df_agg[df_agg['CaseType'] == casetype]['agg_charge_overturn_rate'],\n",
    "        name='Charges Dismissed/Overturned/Amended'\n",
    "    )\n",
    "\n",
    "    data = [trace1, trace2, trace3]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    barmode='group',\n",
    "    xaxis=dict(\n",
    "        title='CHARGES',\n",
    "        titlefont=dict(\n",
    "            family='Arial, sans-serif',\n",
    "            size=18,\n",
    "            color='lightgrey'\n",
    "        ),\n",
    "        showticklabels=True,\n",
    "        automargin=True,\n",
    "        tickangle=45,\n",
    "        tickfont=dict(\n",
    "            family='Arial, sans-serif',\n",
    "            size=14,\n",
    "            color='black'\n",
    "        ),\n",
    "        exponentformat='e',\n",
    "        showexponent='all'\n",
    "    ),\n",
    ")\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~katerdowdy/8.embed\" height=\"800px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_agg_charges(casetype = 'Infraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misdemeanors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~katerdowdy/8.embed\" height=\"800px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_agg_charges(casetype = 'Misdemeanor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Felonies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~katerdowdy/8.embed\" height=\"800px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_agg_charges(casetype = 'Felony')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Civil Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~katerdowdy/8.embed\" height=\"800px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_agg_charges(casetype = 'Civil Violation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features # complainant\n",
    "drop_features = ['Unnamed: 0',\n",
    "                 'level_0',\n",
    "                             'index', \n",
    "                             'HearingDate', \n",
    "                             'HearingResult', \n",
    "                             #'HearingPlea',\n",
    "                             'HearingContinuanceCode',\n",
    "                             'HearingType',\n",
    "                             'HearingCourtroom',\n",
    "                             'fips',\n",
    "                             'FiledDate',\n",
    "                             'Locality',\n",
    "                             'Status',  \n",
    "                             'Address',\n",
    "                             'Gender',\n",
    "                             'Race',\n",
    "                             'Charge', \n",
    "                             'CodeSection', \n",
    "                             'Contested',\n",
    "                             'CaseType', \n",
    "                             'Class',\n",
    "                             'OffenseDate', \n",
    "                             'ArrestDate', \n",
    "                             'AmendedCharge',\n",
    "                             'AmendedCode', \n",
    "                             'AmendedCaseType', \n",
    "                             'FinalDisposition',\n",
    "                             'ProbationTime', \n",
    "                             'ProbationStarts',\n",
    "                             'SentenceTime', \n",
    "                             'SentenceSuspendedTime', \n",
    "                             'ProbationType',\n",
    "                             'OperatorLicenseSuspensionTime',\n",
    "                               'RestrictionEffectiveDate', \n",
    "                             'RestrictionEndDate',\n",
    "                               'OperatorLicenseRestrictionCodes', \n",
    "                             'Fine', \n",
    "                             'Costs', \n",
    "                             'FineCostsDue',\n",
    "                               'FineCostsPaid', \n",
    "                             'FineCostsPaidDate', \n",
    "                             'VASAP', \n",
    "                             'FineCostsPastDue',\n",
    "                             'person_id', \n",
    "                             'person_id_freq',\n",
    "                             'full_fips',\n",
    "                             'Outcome_Positive', \n",
    "                             'Amended', \n",
    "                             'Total_Positive',\n",
    "                            'ChargeType',\n",
    "                            'Court']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['DefenseAttorney'].fillna(0, inplace = True)\n",
    "df_full['Complainant'].fillna(0, inplace = True)\n",
    "df_full['HearingPlea'].fillna(0, inplace = True)\n",
    "\n",
    "def log_odds(x):\n",
    "    return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detail_logreg(county, charge):\n",
    "    try:\n",
    "        logreg = LogisticRegression()\n",
    "        df = df_full[(df_full['Court'] == county) & (df_full['ChargeType'] == charge)]\n",
    "        df_dummied = pd.get_dummies(df, columns = ['DefenseAttorney', 'Complainant', 'HearingPlea'], drop_first = True)\n",
    "        df_model = df_dummied[df_dummied['Contested'] == 1]\n",
    "        X = df_model.drop(columns = drop_features)\n",
    "        features = X.columns\n",
    "        y = df_model['Total_Positive']\n",
    "        baseline = y.value_counts(normalize = True)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)\n",
    "        ss = StandardScaler()\n",
    "        X_train_sc = ss.fit_transform(X_train)\n",
    "        X_test_sc = ss.transform(X_test)\n",
    "        logreg.fit(X_train_sc, y_train)\n",
    "        cv_train = cross_val_score(logreg, X_train_sc, y_train)\n",
    "        cv_test = cross_val_score(logreg, X_test_sc, y_test)\n",
    "    \n",
    "        coefficients = logreg.coef_\n",
    "        coef_df = pd.DataFrame(coefficients, columns = features).T\n",
    "        coef_df['change_odds_ratio'] = coef_df.apply(lambda x: log_odds(x))\n",
    "        coef_df.rename(columns = {0: 'logreg_coefficient'}, inplace = True)\n",
    "        coef_df_top = coef_df.sort_values(by = 'logreg_coefficient', ascending = False).head()\n",
    "        coef_df_bottom = coef_df.sort_values(by = 'logreg_coefficient', ascending = False).tail()\n",
    "        coef_df_all = pd.concat([coef_df_top, coef_df_bottom])\n",
    "    \n",
    "        print(\"Model for {} in {}\".format(charge, county))\n",
    "        print(\"Baseline:\")\n",
    "        print(baseline)\n",
    "        print(\"-----\")\n",
    "        print(\"How Good is This Model?\")\n",
    "        print(\"Train Accuracy Scores:\", cv_train, \"Train Average Accuracy:\", cv_train.mean())\n",
    "        print(\"Test Accuracy Scores:\", cv_test, \"Test Average Accuracy:\", cv_test.mean())\n",
    "        print(\"-----\")\n",
    "        print(\"Factors that Help the Case\")\n",
    "        print(coef_df_top)\n",
    "        print(\"-----\")\n",
    "        print(\"Factors that Hurt the Case\")\n",
    "        print(coef_df_bottom)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dfdd0e9b5f496eac6c5ece05fb995f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='county', options=('Accomack County', 'Albemarle County', 'Alexandr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = interactive(detail_logreg, county = counties, charge = charges)\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Race Make a Difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_race1(county, charge, *args):\n",
    "    df_test = df_full[(df_full['ChargeType'] == charge) &\n",
    "                         (df_full['Court'] == county) &\n",
    "                         (df_full['Contested'] == 1)]\n",
    "    if len(args[0]) == 2:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'])\n",
    "    elif len(args[0]) == 3:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'])\n",
    "    elif len(args[0]) == 4:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][3])]['Total_Positive'])\n",
    "    elif len(args[0]) == 5:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][3])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][4])]['Total_Positive'])\n",
    "    elif len(args[0]) == 6:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][3])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][4])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][5])]['Total_Positive'])\n",
    "\n",
    "    percent_race = df_test['Race'].value_counts(normalize = True)\n",
    "    p_value = test.pvalue\n",
    "   \n",
    "    print(\"Comparing mean outcomes for these populations contesting {} charges in {}:\".format(charge, county))\n",
    "    for i in args[0]:\n",
    "        print(\"    \", i)\n",
    "    print(\"P-value:\", p_value)\n",
    "    if p_value <= 0.01:\n",
    "        print(\"The p-value is sufficiently small that we can reject the null hypothesis and accept the alternative hypothesis: that there is a statistically significant difference in defense outcomes for these groups based on race.\")\n",
    "    if p_value > 0.01:\n",
    "        print(\"The p-value is not small enough to reject the null hypothesis. We cannot draw a conclusion about how outcomes differ by race for this charge.\")\n",
    "    print(\"--------------\")\n",
    "    print(\"Demographic makeup of defendees contesting {} charges in {}:\".format(charge, county))\n",
    "    print(percent_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_race(county, charge, comparison):\n",
    "    df_test = df_full[(df_full['ChargeType'] == charge) &\n",
    "                         (df_full['Court'] == county) &\n",
    "                         (df_full['Contested'] == 1)]\n",
    "    if comparison == 'White, Black':\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == 'White Caucasian(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Black(Non-Hispanic)']['Total_Positive'])\n",
    "    elif comparison == 'White, Black, Latino':\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == 'White Caucasian(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Black(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Hispanic']['Total_Positive'])\n",
    "    elif comparison == 'White, Black, Latino, Asian Or Pacific Islander':\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == 'White Caucasian(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Black(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Hispanic']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Asian Or Pacific Islander']['Total_Positive'])\n",
    "    elif comparison == 'White, Black, Latino, Asian Or Pacific Islander, Native American':\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == 'White Caucasian(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Black(Non-Hispanic)']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Hispanic']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'Asian Or Pacific Islander']['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == 'American Indian']['Total_Positive'])\n",
    "\n",
    "    percent_race = df_test['Race'].value_counts(normalize = True)\n",
    "    p_value = test.pvalue\n",
    "   \n",
    "    print(\"Comparing mean outcomes for these populations contesting {} charges in {}:\".format(charge, county))\n",
    "    print(comparison)\n",
    "    print(\"-----\")\n",
    "    print(\"P-value:\", p_value)\n",
    "    if p_value <= 0.01:\n",
    "        print(\"YES. Race makes a difference.\")\n",
    "        print(\"The p-value is sufficiently small that we can reject the null hypothesis and accept the alternative hypothesis: \"\n",
    "              \"that there is a statistically significant difference in defense outcomes for these groups based on race.\")\n",
    "    if p_value > 0.01:\n",
    "        print(\"Inconclusive.\")\n",
    "        print(\"The p-value is not small enough to reject the null hypothesis. \"\n",
    "              \"We cannot draw a conclusion about how outcomes differ by race for this charge.\")\n",
    "    print(\"--------------\")\n",
    "    print(\"Demographic makeup of defendants contesting {} charges in {}:\".format(charge, county))\n",
    "    print(percent_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = ['White, Black', \n",
    "        'White, Black, Latino',\n",
    "        'White, Black, Latino, Asian Or Pacific Islander',\n",
    "        'White, Black, Latino, Asian Or Pacific Islander, Native American']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d036d08961f496cb173432a06f736a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='county', options=('Accomack County', 'Albemarle County', 'Alexandr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova_race = interactive(anova_race, county = counties, charge = charges, comparison = comps)\n",
    "display(anova_race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Type of Defense Matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummying variables\n",
    "df_dummied = pd.get_dummies(df_full, columns = ['Court', 'Gender', 'Race',\n",
    "                                                'ChargeType'], drop_first = True)\n",
    "\n",
    "# slicing dataframe to just the records contested\n",
    "df_model = df_dummied[df_dummied['Contested'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting X and y variables\n",
    "y = df_model['Total_Positive']\n",
    "\n",
    "X = df_model.drop(columns = ['Unnamed: 0',\n",
    "                             'index', \n",
    "                             'HearingDate', \n",
    "                             'HearingResult', \n",
    "                             'HearingPlea',\n",
    "                             'HearingType', \n",
    "                             'FiledDate', \n",
    "                             'Status', \n",
    "                             'DefenseAttorney', \n",
    "                             'Address',\n",
    "                             'Charge', \n",
    "                             'CodeSection', \n",
    "                             'Contested',\n",
    "                             'CaseType', \n",
    "                             'Class',\n",
    "                             'OffenseDate', \n",
    "                             'ArrestDate', \n",
    "                             'AmendedCharge',\n",
    "                             'AmendedCode', \n",
    "                             'AmendedCaseType', \n",
    "                             'FinalDisposition',\n",
    "                             'Fine', \n",
    "                             'Costs', \n",
    "                             'person_id', \n",
    "                             'Outcome_Positive', \n",
    "                             'Amended', \n",
    "                             'Total_Positive',\n",
    "                             'TimeSinceOffense',\n",
    "                             'fips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking to make sure no nulls\n",
    "X.isnull().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting list of features\n",
    "features = X.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking baseline (59% positive outcome)\n",
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# same for test\n",
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scale\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(logreg, X_train_sc, y_train)\n",
    "print(\"Train CV Scores:\", cv_scores)\n",
    "print(\"Average Train CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(logreg, X_test_sc, y_test)\n",
    "print(\"Test CV Scores:\", cv_scores)\n",
    "print(\"Average Test CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our train and test scores are pretty close so I don't think there's overfitting here. Accuracy is about 5% over baseline, which isn't great but also not terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg.coef_\n",
    "\n",
    "coef_df = pd.DataFrame(coefficients, columns = features).T\n",
    "\n",
    "def log_odds(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "coef_df['change_odds_ratio'] = coef_df.apply(lambda x: log_odds(x))\n",
    "\n",
    "coef_df.rename(columns = {0: 'logreg_coefficient'}, inplace = True)\n",
    "\n",
    "coef_df.sort_values(by = 'logreg_coefficient').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Logistic Regression, race (Black, White, and Latino) and being charged with a Misdemeanor DWI/DUI or Seatbelt Infraction are the most negative coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.sort_values(by = 'logreg_coefficient').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Logistic Regression, having a lawyer is the most positive coefficient, followed by being charged with speeding, license/permit/tag issues, and expired registration/inspection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_preds = logreg.predict_proba(X_test_sc)\n",
    "prob_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prob_preds, bins = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_preds = logreg.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, outcome_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, outcome_preds).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "print(\"-----\")\n",
    "print(\"Accuracy: %s\" % ((tp + tn) / (tn + fp + fn + tp)))\n",
    "print(\"Misclassification Rate: %s\" % ((fp + fn) / (tn + fp + fn + tp)))\n",
    "print(\"-----\")\n",
    "print(\"Sensitivity/Recall (True Positive Rate): %s\" % ((tp) / (tp + fn)))\n",
    "print(\"Specificity (True Negative Rate): %s\" % ((tn) / (tn + fp)))\n",
    "print(\"False Positive Rate: %s\" % ((fp) / (tp + fn)))\n",
    "print(\"Precision: %s\" % ((tp) / (tp + fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to use a model to make recommendations to people who didn't have to contest their charges on whether or not to go to court (and risk having to pay court fees on top of their fines and a lawyer), we would want to be minimizing our False Positives (so get our Precision rate closer to 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training scores\n",
    "cv_scores = cross_val_score(dt, X_train_sc, y_train)\n",
    "print(\"Train CV Scores:\", cv_scores)\n",
    "print(\"Average Train CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scores\n",
    "cv_scores = cross_val_score(logreg, X_test_sc, y_test)\n",
    "print(\"Test CV Scores:\", cv_scores)\n",
    "print(\"Average Test CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree doesn't seem to be doing better than the Logistic Regression; I think the existing model is too simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = dt.feature_importances_\n",
    "importance_dict = dict(zip(features, importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that had the greatest feature importance weight: \n",
    "- 'Expired Registration/Inspection': 0.0248\n",
    "- 'Gender_Male': 0.0237\n",
    "- 'ChargeType_INF: Speeding': 0.0168\n",
    "- 'Race_Black(Non-Hispanic)': 0.0129\n",
    "- 'Race_White Caucasian(Non-Hispanic)': 0.0124\n",
    "- 'Court_Fairfax County': 0.0123\n",
    "- 'ChargeType_INF: Seatbelt': 0.0116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training scores\n",
    "cv_scores = cross_val_score(rf, X_train_sc, y_train)\n",
    "print(\"Train CV Scores:\", cv_scores)\n",
    "print(\"Average Train CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scores\n",
    "cv_scores = cross_val_score(logreg, X_test_sc, y_test)\n",
    "print(\"Test CV Scores:\", cv_scores)\n",
    "print(\"Average Test CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County-level / Infraction-level Recommendation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features # complainant\n",
    "drop_features = ['Unnamed: 0',\n",
    "                 'level_0',\n",
    "                             'index', \n",
    "                             'HearingDate', \n",
    "                             'HearingResult', \n",
    "                             #'HearingPlea',\n",
    "                             'HearingContinuanceCode',\n",
    "                             'HearingType',\n",
    "                             'HearingCourtroom',\n",
    "                             'fips',\n",
    "                             'FiledDate',\n",
    "                             'Locality',\n",
    "                             'Status',  \n",
    "                             'Address',\n",
    "                             'Gender',\n",
    "                             'Race',\n",
    "                             'Charge', \n",
    "                             'CodeSection', \n",
    "                             'Contested',\n",
    "                             'CaseType', \n",
    "                             'Class',\n",
    "                             'OffenseDate', \n",
    "                             'ArrestDate', \n",
    "                             'AmendedCharge',\n",
    "                             'AmendedCode', \n",
    "                             'AmendedCaseType', \n",
    "                             'FinalDisposition',\n",
    "                             'ProbationTime', \n",
    "                             'ProbationStarts',\n",
    "                             'SentenceTime', \n",
    "                             'SentenceSuspendedTime', \n",
    "                             'ProbationType',\n",
    "                             'OperatorLicenseSuspensionTime',\n",
    "                               'RestrictionEffectiveDate', \n",
    "                             'RestrictionEndDate',\n",
    "                               'OperatorLicenseRestrictionCodes', \n",
    "                             'Fine', \n",
    "                             'Costs', \n",
    "                             'FineCostsDue',\n",
    "                               'FineCostsPaid', \n",
    "                             'FineCostsPaidDate', \n",
    "                             'VASAP', \n",
    "                             'FineCostsPastDue',\n",
    "                             'person_id', \n",
    "                             'person_id_freq',\n",
    "                             'full_fips',\n",
    "                             'Outcome_Positive', \n",
    "                             'Amended', \n",
    "                             'Total_Positive',\n",
    "                            'ChargeType',\n",
    "                            'Court']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['DefenseAttorney'].fillna(0, inplace = True)\n",
    "df_full['Complainant'].fillna(0, inplace = True)\n",
    "df_full['HearingPlea'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_odds(x):\n",
    "    return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detail_logreg(county, charge):\n",
    "    try:\n",
    "        logreg = LogisticRegression()\n",
    "        df = df_full[(df_full['Court'] == county) & (df_full['ChargeType'] == charge)]\n",
    "        df_dummied = pd.get_dummies(df, columns = ['DefenseAttorney', 'Complainant', 'HearingPlea'], drop_first = True)\n",
    "        df_model = df_dummied[df_dummied['Contested'] == 1]\n",
    "        X = df_model.drop(columns = drop_features)\n",
    "        features = X.columns\n",
    "        y = df_model['Total_Positive']\n",
    "        baseline = y.value_counts(normalize = True)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)\n",
    "        ss = StandardScaler()\n",
    "        X_train_sc = ss.fit_transform(X_train)\n",
    "        X_test_sc = ss.transform(X_test)\n",
    "        logreg.fit(X_train_sc, y_train)\n",
    "        cv_train = cross_val_score(logreg, X_train_sc, y_train)\n",
    "        cv_test = cross_val_score(logreg, X_test_sc, y_test)\n",
    "    \n",
    "        coefficients = logreg.coef_\n",
    "        coef_df = pd.DataFrame(coefficients, columns = features).T\n",
    "        coef_df['change_odds_ratio'] = coef_df.apply(lambda x: log_odds(x))\n",
    "        coef_df.rename(columns = {0: 'logreg_coefficient'}, inplace = True)\n",
    "        coef_df_top = coef_df.sort_values(by = 'logreg_coefficient', ascending = False).head()\n",
    "        coef_df_bottom = coef_df.sort_values(by = 'logreg_coefficient', ascending = False).tail()\n",
    "        coef_df_all = pd.concat([coef_df_top, coef_df_bottom])\n",
    "    \n",
    "        print(\"Scores for {} in {}\".format(charge, county))\n",
    "        print(\"Baseline:\", baseline)\n",
    "        print(\"Train Accuracy Scores:\", cv_train, \"Train Average Accuracy:\", cv_train.mean())\n",
    "        print(\"Test Accuracy Scores:\", cv_test, \"Test Average Accuracy:\", cv_test.mean())\n",
    "        print(\"-----\")\n",
    "        print(\"Factors that Help the Case (Top) and Hurt the Case (Bottom)\")\n",
    "        return coef_df_all\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = interactive(detail_logreg, county = counties, charge = charges)\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is there a statistically significant difference between outcomes based only on race?\n",
    "\n",
    "Given the simplicity of the model, I want to look more specifically at one charge compared against different court districts in densely populated areas and more rural areas to see if there are statistically significant differences in outcomes based on race. Since speeding infractions are so prevalent, I'll use those for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_race(county, charge, *args):\n",
    "    df_test = df_full[(df_full['ChargeType'] == charge) &\n",
    "                         (df_full['Court'] == county) &\n",
    "                         (df_full['Contested'] == 1)]\n",
    "    if len(args[0]) == 2:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'])\n",
    "    elif len(args[0]) == 3:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'])\n",
    "    elif len(args[0]) == 4:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][3])]['Total_Positive'])\n",
    "    elif len(args[0]) == 5:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][3])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][4])]['Total_Positive'])\n",
    "    elif len(args[0]) == 6:\n",
    "        test = stats.f_oneway(df_test[df_test['Race'] == str(args[0][0])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][1])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][2])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][3])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][4])]['Total_Positive'],\n",
    "                          df_test[df_test['Race'] == str(args[0][5])]['Total_Positive'])\n",
    "\n",
    "    percent_race = df_test['Race'].value_counts(normalize = True)\n",
    "    p_value = test.pvalue\n",
    "   \n",
    "    print(\"Comparing mean outcomes for these populations contesting {} charges in {}:\".format(charge, county))\n",
    "    for i in args[0]:\n",
    "        print(\"    \", i)\n",
    "    print(\"P-value:\", p_value)\n",
    "    if p_value <= 0.01:\n",
    "        print(\"The p-value is sufficiently small that we can reject the null hypothesis and accept the alternative hypothesis: that there is a statistically significant difference in defense outcomes for these groups based on race.\")\n",
    "    if p_value > 0.01:\n",
    "        print(\"The p-value is not small enough to reject the null hypothesis. We cannot draw a conclusion about how outcomes differ by race for this charge.\")\n",
    "    print(\"--------------\")\n",
    "    print(\"Demographic makeup of defendees contesting {} charges in {}:\".format(charge, county))\n",
    "    print(percent_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling function\n",
    "args = ('White Caucasian(Non-Hispanic)', 'Black(Non-Hispanic)', 'Asian Or Pacific Islander')\n",
    "anova_race('Fairfax County', 'INF: Speeding', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_defense(county, charge, only_lawyers = True):\n",
    "    df_test = df_full[(df_full['ChargeType'] == charge) &\n",
    "                         (df_full['Court'] == county) &\n",
    "                         (df_full['Contested'] == 1)]\n",
    "    if only_lawyers == False:\n",
    "        test = stats.f_oneway(df_test[(df_test['HadLawyer'] == 1) &\n",
    "                                 (df_test['PublicDefender'] == 0)]['Total_Positive'],\n",
    "                   df_test[(df_test['HadLawyer'] == 1) &\n",
    "                          (df_test['PublicDefender'] == 1)]['Total_Positive'],\n",
    "                   df_test[df_test['HadLawyer'] == 0]['Total_Positive'])\n",
    "        print(\"Comparing mean outcomes for defendees with public defenders, private lawyers, and no lawyers contesting {} charges in {} based on defense strategy:\".format(charge, county))\n",
    "    \n",
    "    elif only_lawyers == True:\n",
    "        test = stats.f_oneway(df_test[(df_test['HadLawyer'] == 1) &\n",
    "                                 (df_test['PublicDefender'] == 0)]['Total_Positive'],\n",
    "                   df_test[(df_test['HadLawyer'] == 1) &\n",
    "                          (df_test['PublicDefender'] == 1)]['Total_Positive'])\n",
    "        print(\"Comparing mean outcomes for defendees with public defenders and private lawyers \"\n",
    "              \"contesting {} charges in {} based on defense strategy:\".format(charge, county))\n",
    "    \n",
    "    percent_had_lawyer = df_test['HadLawyer'].value_counts(normalize = True)\n",
    "    percent_had_pd = df_test[df_test['HadLawyer'] == 1]['PublicDefender'].value_counts(normalize = True)\n",
    "    p_value = test.pvalue\n",
    "    \n",
    "    print(\"P-value:\", p_value)\n",
    "    if p_value <= 0.01:\n",
    "        print(\"The p-value is sufficiently small that we can reject the null hypothesis and \"\n",
    "        \"accept the alternative hypothesis: that there is a statistically significant difference \"\n",
    "        \"in defense outcomes for these groups based on defense strategy.\")\n",
    "    if p_value > 0.01:\n",
    "        print(\"The p-value is not small enough to reject the null hypothesis. We cannot draw \"\n",
    "        \"a conclusion about how outcomes differ by defense strategy for this charge.\")\n",
    "    print(\"--------------\")\n",
    "    print(\"Defendees who had lawyers to help contest {} charges in {}:\".format(charge, county))\n",
    "    print(percent_had_lawyer)\n",
    "    print(\"Of those with lawyers, the percentage with public defenders:\")\n",
    "    print(percent_had_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_defense('Fairfax County', 'MIS: Drug-related Offenses', only_lawyers = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INF: Speeding \n",
    "# counties around the three main population centers in Virginia\n",
    "fairfax_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                                (df_full['Court'] == 'Fairfax County')]\n",
    "\n",
    "vabeach_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                                (df_full['Court'] == 'Virginia Beach City')]\n",
    "\n",
    "henrico_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                             (df_full['Court'] == 'Henrico County')]\n",
    "\n",
    "# more rural counties\n",
    "henry_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                           (df_full['Court'] == 'Henry County')]\n",
    "\n",
    "augusta_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                             (df_full['Court'] == 'Augusta County')]\n",
    "\n",
    "wythe_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                             (df_full['Court'] == 'Wythe County')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial disparity in Fairfax County\n",
    "stats.f_oneway(fairfax_speedingINF[(fairfax_speedingINF['Race'] == \n",
    "                                   'White Caucasian(Non-Hispanic)') &\n",
    "                                  (fairfax_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              fairfax_speedingINF[(fairfax_speedingINF['Race'] == \n",
    "                                   'Black(Non-Hispanic)') & \n",
    "                                 (fairfax_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              fairfax_speedingINF[(fairfax_speedingINF['Race'] == \n",
    "                                   'Hispanic') & \n",
    "                                  (fairfax_speedingINF['Contested'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is sufficiently small that we can reject the null hypothesis that the average outcome for different racial groups going to court in Fairfax to fight speeding infraction tickets is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial disparity in Henry County\n",
    "stats.f_oneway(henry_speedingINF[(henry_speedingINF['Race'] == \n",
    "                                   'White Caucasian(Non-Hispanic)') &\n",
    "                                  (henry_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              henry_speedingINF[(henry_speedingINF['Race'] == \n",
    "                                   'Black(Non-Hispanic)') & \n",
    "                                 (henry_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              henry_speedingINF[(henry_speedingINF['Race'] == \n",
    "                                   'Hispanic') & \n",
    "                                  (henry_speedingINF['Contested'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is not small enought to reject the null hypothesis that the average outcome for different racial groups going to court in Henry County to fight speeding infraction tickets is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial disparity in Henrico County\n",
    "stats.f_oneway(henrico_speedingINF[(henrico_speedingINF['Race'] == \n",
    "                                   'White Caucasian(Non-Hispanic)') &\n",
    "                                  (henrico_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              henrico_speedingINF[(henrico_speedingINF['Race'] == \n",
    "                                   'Black(Non-Hispanic)') & \n",
    "                                 (henrico_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              henrico_speedingINF[(henrico_speedingINF['Race'] == \n",
    "                                   'Hispanic') & \n",
    "                                  (henrico_speedingINF['Contested'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is sufficiently small that we can reject the null hypothesis that the average outcome for different racial groups going to court in Henrico County to fight speeding infraction tickets is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial disparity in Virginia Beach\n",
    "stats.f_oneway(vabeach_speedingINF[(vabeach_speedingINF['Race'] == \n",
    "                                   'White Caucasian(Non-Hispanic)') &\n",
    "                                  (vabeach_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              vabeach_speedingINF[(vabeach_speedingINF['Race'] == \n",
    "                                   'Black(Non-Hispanic)') & \n",
    "                                 (vabeach_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              vabeach_speedingINF[(vabeach_speedingINF['Race'] == \n",
    "                                   'Hispanic') & \n",
    "                                  (vabeach_speedingINF['Contested'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is sufficiently small that we can reject the null hypothesis that the average outcome for different racial groups going to court in Virginia Beach to fight speeding infraction tickets is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial disparity in Augusta County\n",
    "stats.f_oneway(augusta_speedingINF[(augusta_speedingINF['Race'] == \n",
    "                                   'White Caucasian(Non-Hispanic)') &\n",
    "                                  (augusta_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              augusta_speedingINF[(augusta_speedingINF['Race'] == \n",
    "                                   'Black(Non-Hispanic)') & \n",
    "                                 (augusta_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              augusta_speedingINF[(augusta_speedingINF['Race'] == \n",
    "                                   'Hispanic') & \n",
    "                                  (augusta_speedingINF['Contested'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is sufficiently small that we can reject the null hypothesis that the average outcome for different racial groups going to court in Augusta County to fight speeding infraction tickets is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# racial disparity in Wythe County\n",
    "stats.f_oneway(wythe_speedingINF[(wythe_speedingINF['Race'] == \n",
    "                                   'White Caucasian(Non-Hispanic)') &\n",
    "                                  (wythe_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              wythe_speedingINF[(wythe_speedingINF['Race'] == \n",
    "                                   'Black(Non-Hispanic)') & \n",
    "                                 (wythe_speedingINF['Contested'] == 1)]['Total_Positive'],\n",
    "              wythe_speedingINF[(wythe_speedingINF['Race'] == \n",
    "                                   'Hispanic') & \n",
    "                                  (wythe_speedingINF['Contested'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is not small enought to reject the null hypothesis that the average outcome for different racial groups going to court in Wythe County to fight speeding infraction tickets is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demographic makeup of 6 Counties' Speeding Infraction caseloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairfax_speedingINF['Race'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vabeach_speedingINF['Race'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "henrico_speedingINF['Race'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "henry_speedingINF['Race'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augusta_speedingINF['Race'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wythe_speedingINF['Race'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Is there a statistically significant difference in outcomes when a defendant is represented by a private lawyer or public defender?\n",
    "\n",
    "For this question, I'll look at three different types of charges and compare outcomes with no lawyers, with private lawyers, and with public defenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 300)\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for counties that have public defenders for comparison to Fairfax\n",
    "df_full[(df_full['HadLawyer'] == 1) & (df_full['PublicDefender'] == 1)]['Court'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairfax County, three different charges\n",
    "fairfax_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                                (df_full['Court'] == 'Fairfax County') &\n",
    "                             (df_full['Contested'] == 1)]\n",
    "\n",
    "fairfax_drugsMIS = df_full[(df_full['ChargeType'] == 'MIS: Drug-related Offenses') &\n",
    "                                (df_full['Court'] == 'Fairfax County') &\n",
    "                          (df_full['Contested'] == 1)]\n",
    "\n",
    "fairfax_recklessMIS = df_full[(df_full['ChargeType'] == 'MIS: Reckless Driving') &\n",
    "                             (df_full['Court'] == 'Fairfax County') &\n",
    "                             (df_full['Contested'] == 1)]\n",
    "\n",
    "# Henry County\n",
    "newport_speedingINF = df_full[(df_full['ChargeType'] == 'INF: Speeding') &\n",
    "                                (df_full['Court'] == 'Newport News City') &\n",
    "                           (df_full['Contested'] == 1)]\n",
    "\n",
    "newport_drugsMIS = df_full[(df_full['ChargeType'] == 'MIS: Drug-related Offenses') &\n",
    "                                (df_full['Court'] == 'Newport News City') &\n",
    "                        (df_full['Contested'] == 1)]\n",
    "\n",
    "newport_recklessMIS = df_full[(df_full['ChargeType'] == 'MIS: Reckless Driving') &\n",
    "                             (df_full['Court'] == 'Newport News City') &\n",
    "                           (df_full['Contested'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Speeding Infractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for a speeding ticket in Fairfax County\n",
    "stats.f_oneway(fairfax_speedingINF[(fairfax_speedingINF['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (fairfax_speedingINF['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_speedingINF[(fairfax_speedingINF['HadLawyer'] == 0) & # self-defense\n",
    "                                  (fairfax_speedingINF['PublicDefender'] == 0)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is sufficiently small that we can reject the null hypothesis that the average outcome for people who hire lawyers and don't hire lawyers to fight speeding tickets in Fairfax Virginia is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for a speeding ticket in Henry County\n",
    "stats.f_oneway(newport_speedingINF[(newport_speedingINF['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (newport_speedingINF['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              newport_speedingINF[(newport_speedingINF['HadLawyer'] == 0) & # self-defense\n",
    "                                  (newport_speedingINF['PublicDefender'] == 0)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a significance level of $\\alpha = 0.05$,  the p-value is sufficiently small that we can reject the null hypothesis that the average outcome for people who hire lawyers and don't hire lawyers to fight speeding tickets in Henry County is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drug-related Offenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for a drug-related offense in Fairfax County\n",
    "stats.f_oneway(fairfax_drugsMIS[(fairfax_drugsMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (fairfax_drugsMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_drugsMIS[(fairfax_drugsMIS['HadLawyer'] == 0) & # self-defense\n",
    "                                  (fairfax_drugsMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_drugsMIS[(fairfax_drugsMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (fairfax_drugsMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer/public defender for a drug-related offense in Fairfax\n",
    "stats.f_oneway(fairfax_drugsMIS[(fairfax_drugsMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (fairfax_drugsMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_drugsMIS[(fairfax_drugsMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (fairfax_drugsMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is significantly small enough in the first test to reject the null hypothesis that outcomes are the same whether someone defends themselves against a drug charge, hires a lawyer, or a public defender. Looking at the second test, the p-value is not sufficiently small to reject the null hypothesis (that outcomes for those who hired private lawyers and public defenders is the same). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for a drug-related offense in Fairfax County\n",
    "stats.f_oneway(newport_drugsMIS[(newport_drugsMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (newport_drugsMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              newport_drugsMIS[(newport_drugsMIS['HadLawyer'] == 0) & # self-defense\n",
    "                                  (newport_drugsMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              newport_drugsMIS[(newport_drugsMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (newport_drugsMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for a drug-related offense in Fairfax County\n",
    "stats.f_oneway(newport_drugsMIS[(newport_drugsMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (newport_drugsMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              newport_drugsMIS[(newport_drugsMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (newport_drugsMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first test, the p-value is sufficiently small to reject the null hypothesis that there is a difference in outcomes for defendants fighting drug charges in Newport News based on whether they hired lawyers, defended themselves, or had public defenders. So outcomes are probably different; in the second test, the p-value is still sufficiently small for us to reject the null that there is no difference between hiring a private lawyer and public defender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reckless Driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for reckless driving in Fairfax County\n",
    "stats.f_oneway(fairfax_recklessMIS[(fairfax_recklessMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (fairfax_recklessMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_recklessMIS[(fairfax_recklessMIS['HadLawyer'] == 0) & # self-defense\n",
    "                                  (fairfax_recklessMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_recklessMIS[(fairfax_recklessMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (fairfax_recklessMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for reckless driving in Fairfax County\n",
    "stats.f_oneway(fairfax_recklessMIS[(fairfax_recklessMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (fairfax_recklessMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              fairfax_recklessMIS[(fairfax_recklessMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (fairfax_recklessMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is significantly small to reject the null hypothesis and accept the alternative (that there is a statistically significant difference in outcome for reckless driving cases in Fairfax County based on whether someone hires a lawyer, defends themselves, or hires a public defender.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiring a lawyer for a drug-related offense in Fairfax County\n",
    "stats.f_oneway(newport_recklessMIS[(newport_recklessMIS['HadLawyer'] == 1) & # private lawyer\n",
    "                                   (newport_recklessMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              newport_recklessMIS[(newport_recklessMIS['HadLawyer'] == 0) & # self-defense\n",
    "                                  (newport_recklessMIS['PublicDefender'] == 0)]['Total_Positive'],\n",
    "              newport_recklessMIS[(newport_recklessMIS['HadLawyer'] == 1) & # public defender\n",
    "                                  (newport_recklessMIS['PublicDefender'] == 1)]['Total_Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is not sufficiently small to reject the null hypothesis that the average outcome for reckless driving defendants is the same (whether they hire private lawyers, public defenders, or defend themselves.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
